NAME=/mnt/nas_home/fs-xlt/experiments/sa_ttrain_all;
SCRIPT=nusax_senti_ttrain_all.sh;
#SRC_DIR?=/mnt/nas_home/mp939/projects/few-shot;
SRC_DIR=/mnt/nas_home/aja63/projects/fs-xlt/few-shot;
CONDA_ENV=fs-xlt-adapt;
CONDA_REPLACE=few-shot;

ADAPTATION_METHOD () =
    sft #|
    #adapters
;

BASE_MODEL?, BASE_MODEL_SHORT (), BASE_MODEL_SFT_IDENTIFIER? =
    xlm-roberta-base, xlmrbase, xlmr
;

SOURCE_LANG? = id;

DATA_CONFIG (), NUM_TARGET_SHOTS (ts) =
    nusa_ttrain_all_nllb_langs_3.3B.json (nllb3.3B), 0
    #nusa_ttrain_all_nllb_langs_1.3B.json (nllb1.3B), 0 |
    #nusa_ttrain_all_nllb_langs_600M.json (nllb600M), 0
    #nusa_ttrain_multisource_fs_3.3B.json, 100
;
TARGET_UPSAMPLING? = 10;

LANGUAGE_ADAPTATION (la) =
    no
    #yes
;

# Task fine-tuning attributes
SFT_PARAMS_NUM? =
    14155776
;
FULL_FT_EPOCHS (epochs), SPARSE_FT_EPOCHS () =
    3, 10
;
# MAX_SEQ_LENGTH? = 256;
BATCH_SIZE? = 16;
GRADIENT_ACCUMULATION_STEPS? = 1;
LEARNING_RATE? = 2e-5;
EVAL_STEPS? = 250;
